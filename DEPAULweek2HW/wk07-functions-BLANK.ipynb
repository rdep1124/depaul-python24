{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5320cbbf",
   "metadata": {},
   "source": [
    "# Homework for Week 7\n",
    "## Functions and Downloading documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5db5b3",
   "metadata": {},
   "source": [
    "### Write modular functions for the following:\n",
    "\n",
    "1. Making a ```request```\n",
    "2. Converting a ```response``` into ```soup```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b96b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. code here for requests function (create cells if/as needed)\n",
    "from bs4 import BeautifulSoup  ## scrape info from web pages\n",
    "import requests\n",
    "\n",
    "def requestget(url):\n",
    "    response = requests.get(url)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed087ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. code here for response function (create cells if/as needed)\n",
    "def responsetoSoup(response):\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350b62c",
   "metadata": {},
   "source": [
    "### 3. Demo downloading files from websites \n",
    "\n",
    "There are ```txt``` and ```pdf``` files <a href=\"https://sandeepmj.github.io/scrape-example-page/pages.html\">on this site</a>. During class we downloaded on e set of text files and one set of PDF files.\n",
    "\n",
    "Now download **ALL files at one time**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a209478",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here (create cells if/as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53bc4ff6-b0e9-4ff2-8f04-3ffcf5927a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requestget(\"https://sandeepmj.github.io/scrape-example-page/pages.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "636e6973-7fef-4f34-bb39-b8c6c58a4f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/pdf_1.pdf\">1</a>,\n",
       " <a href=\"files/pdf_2.pdf\">2</a>,\n",
       " <a href=\"files/pdf_3.pdf\">3</a>,\n",
       " <a href=\"files/pdf_4.pdf\">4</a>,\n",
       " <a href=\"files/pdf_5.pdf\">5</a>,\n",
       " <a href=\"files/pdf_6.pdf\">6</a>,\n",
       " <a href=\"files/pdf_7.pdf\">7</a>,\n",
       " <a href=\"files/pdf_8.pdf\">8</a>,\n",
       " <a href=\"files/pdf_9.pdf\">9</a>,\n",
       " <a href=\"files/pdf_10.pdf\">10</a>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://sandeepmj.github.io/scrape-example-page/pages.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "pdfaTags = soup.find(\"ul\", class_=\"pdfs\").find_all(\"a\")\n",
    "pdfaTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed1e3014-9611-4a52-a6a2-09884fe3f4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ul class=\"txts downloadable\">\n",
       " <p class=\"pages\">Download this first set of text documents</p>\n",
       " <li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
       " <li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
       " </ul>,\n",
       " <ul class=\"txts downloadable\">\n",
       " <p class=\"pages\">Download this second set of text documents</p>\n",
       " <li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>\n",
       " <li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtTags = soup.find_all(\"ul\", class_=\"txts\")\n",
    "txtTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39e07acb-7013-45d8-87fd-90ce11d43659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_02.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_03.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_04.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_05.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_06.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_07.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_08.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_09.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_10.txt\">10</a>],\n",
       " [<a href=\"files/text_doc_A.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_B.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_C.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_D.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_E.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_F.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_G.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_H.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_I.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_J.txt\">10</a>]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_links = []\n",
    "for txtpage in txtTags:\n",
    "    links = txtpage.find_all(\"a\")\n",
    "    all_links.append(links)\n",
    "all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2625081-a1d1-4e5a-8764-3e7b243599ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/pdf_1.pdf\">1</a>,\n",
       " <a href=\"files/pdf_2.pdf\">2</a>,\n",
       " <a href=\"files/pdf_3.pdf\">3</a>,\n",
       " <a href=\"files/pdf_4.pdf\">4</a>,\n",
       " <a href=\"files/pdf_5.pdf\">5</a>,\n",
       " <a href=\"files/pdf_6.pdf\">6</a>,\n",
       " <a href=\"files/pdf_7.pdf\">7</a>,\n",
       " <a href=\"files/pdf_8.pdf\">8</a>,\n",
       " <a href=\"files/pdf_9.pdf\">9</a>,\n",
       " <a href=\"files/pdf_10.pdf\">10</a>,\n",
       " [<a href=\"files/text_doc_01.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_02.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_03.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_04.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_05.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_06.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_07.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_08.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_09.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_10.txt\">10</a>],\n",
       " [<a href=\"files/text_doc_A.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_B.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_C.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_D.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_E.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_F.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_G.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_H.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_I.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_J.txt\">10</a>]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "every_link = pdfaTags + all_links\n",
    "\n",
    "every_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c61fc1d-d14c-4925-85bb-364a88e5e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0dc62651-b9ad-47a0-8636-90857aaf5f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>,\n",
       " <a href=\"files/text_doc_A.txt\">1</a>,\n",
       " <a href=\"files/text_doc_B.txt\">2</a>,\n",
       " <a href=\"files/text_doc_C.txt\">3</a>,\n",
       " <a href=\"files/text_doc_D.txt\">4</a>,\n",
       " <a href=\"files/text_doc_E.txt\">5</a>,\n",
       " <a href=\"files/text_doc_F.txt\">6</a>,\n",
       " <a href=\"files/text_doc_G.txt\">7</a>,\n",
       " <a href=\"files/text_doc_H.txt\">8</a>,\n",
       " <a href=\"files/text_doc_I.txt\">9</a>,\n",
       " <a href=\"files/text_doc_J.txt\">10</a>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_all_link = list(itertools.chain(*all_links))\n",
    "\n",
    "updated_all_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ea26b6c-426e-45d6-85e6-7708b58a821d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/pdf_1.pdf\">1</a>,\n",
       " <a href=\"files/pdf_2.pdf\">2</a>,\n",
       " <a href=\"files/pdf_3.pdf\">3</a>,\n",
       " <a href=\"files/pdf_4.pdf\">4</a>,\n",
       " <a href=\"files/pdf_5.pdf\">5</a>,\n",
       " <a href=\"files/pdf_6.pdf\">6</a>,\n",
       " <a href=\"files/pdf_7.pdf\">7</a>,\n",
       " <a href=\"files/pdf_8.pdf\">8</a>,\n",
       " <a href=\"files/pdf_9.pdf\">9</a>,\n",
       " <a href=\"files/pdf_10.pdf\">10</a>,\n",
       " <a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>,\n",
       " <a href=\"files/text_doc_A.txt\">1</a>,\n",
       " <a href=\"files/text_doc_B.txt\">2</a>,\n",
       " <a href=\"files/text_doc_C.txt\">3</a>,\n",
       " <a href=\"files/text_doc_D.txt\">4</a>,\n",
       " <a href=\"files/text_doc_E.txt\">5</a>,\n",
       " <a href=\"files/text_doc_F.txt\">6</a>,\n",
       " <a href=\"files/text_doc_G.txt\">7</a>,\n",
       " <a href=\"files/text_doc_H.txt\">8</a>,\n",
       " <a href=\"files/text_doc_I.txt\">9</a>,\n",
       " <a href=\"files/text_doc_J.txt\">10</a>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "every_link = pdfaTags + updated_all_link\n",
    "\n",
    "every_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dea21b52-85e2-4810-b54c-f3866b9177b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://sandeepmj.github.io/scrape-example-page/files/pdf_1.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/pdf_2.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/pdf_3.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/pdf_4.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/pdf_5.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/pdf_6.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/pdf_7.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/pdf_8.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/pdf_9.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/pdf_10.pdf',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_01.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_02.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_03.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_04.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_05.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_06.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_07.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_08.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_09.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_10.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_A.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_B.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_C.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_D.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_E.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_F.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_G.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_H.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_I.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_J.txt']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseurl = \"https://sandeepmj.github.io/scrape-example-page/\"\n",
    "pdflinks = [baseurl + link.get(\"href\") for link in every_link]\n",
    "pdflinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a45551cd-3fa1-4e6a-8bc6-f44aab4aa0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import time\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0ab10e5-3513-4934-aed7-93ef3218a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snoozer(startTime, endTime):\n",
    "    '''\n",
    "    This function picks a random amount of time between 2 numbers\n",
    "    para1: minimum amount of seconds before next scrape\n",
    "    para2: maximum amount of time before it begins next scrape\n",
    "    '''\n",
    "    snoozer = randrange(startTime, endTime) \n",
    "    print(f\"snoozing for {snoozer} seconds before next scrape\")\n",
    "    time.sleep(snoozer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c33e0-b9f2-475c-9562-09745115189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading link 1 of 30\n",
      "snoozing for 7 seconds before next scrape\n",
      "Downloading link 2 of 30\n",
      "snoozing for 8 seconds before next scrape\n",
      "Downloading link 3 of 30\n",
      "snoozing for 5 seconds before next scrape\n",
      "Downloading link 4 of 30\n",
      "snoozing for 6 seconds before next scrape\n",
      "Downloading link 5 of 30\n",
      "snoozing for 9 seconds before next scrape\n",
      "Downloading link 6 of 30\n",
      "snoozing for 5 seconds before next scrape\n",
      "Downloading link 7 of 30\n",
      "snoozing for 5 seconds before next scrape\n",
      "Downloading link 8 of 30\n",
      "snoozing for 9 seconds before next scrape\n",
      "Downloading link 9 of 30\n",
      "snoozing for 8 seconds before next scrape\n",
      "Downloading link 10 of 30\n",
      "snoozing for 9 seconds before next scrape\n",
      "Downloading link 11 of 30\n",
      "snoozing for 8 seconds before next scrape\n",
      "Downloading link 12 of 30\n",
      "snoozing for 9 seconds before next scrape\n",
      "Downloading link 13 of 30\n",
      "snoozing for 8 seconds before next scrape\n",
      "Downloading link 14 of 30\n",
      "snoozing for 6 seconds before next scrape\n",
      "Downloading link 15 of 30\n",
      "snoozing for 6 seconds before next scrape\n",
      "Downloading link 16 of 30\n",
      "snoozing for 8 seconds before next scrape\n",
      "Downloading link 17 of 30\n",
      "snoozing for 9 seconds before next scrape\n"
     ]
    }
   ],
   "source": [
    "link_count = 1\n",
    "start_range, end_range = 5,10\n",
    "\n",
    "for pdflink in pdflinks:\n",
    "    print(f\"Downloading link {link_count} of {len(pdflinks)}\")\n",
    "    link_count += 1 \n",
    "    ##downloading docs\n",
    "    wget.download(pdflink)\n",
    "    my_snoozer(start_range, end_range)\n",
    "print(f\"Done downloading {link_count} of {len(pdflinks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddd1bf-630a-469d-94ec-101723ab8807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
